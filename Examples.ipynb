{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs on ImageWoof dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.003; eff_lr: 0.003; size: 224; alpha: 0.99; mom: 0.9; eps: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.240811</td>\n",
       "      <td>2.699920</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.038033</td>\n",
       "      <td>2.046215</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.876917</td>\n",
       "      <td>1.999214</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.690265</td>\n",
       "      <td>1.854352</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.557420</td>\n",
       "      <td>1.806944</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run train.py --woof 1 --size 224 --bs 64 --mixup 0  --epoch 5  --lr 3e-3 --arch 'efficientnetB0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01; eff_lr: 0.01; size: 224; alpha: 0.99; mom: 0.9; eps: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.229320</td>\n",
       "      <td>2.242583</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.029476</td>\n",
       "      <td>2.116672</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.886695</td>\n",
       "      <td>1.934686</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.725709</td>\n",
       "      <td>1.741676</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.601069</td>\n",
       "      <td>1.690612</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run train.py --woof 1 --size 224 --bs 64 --mixup 0  --epoch 5  --lr 1e-2 --arch 'efficientnetB0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01; eff_lr: 0.01; size: 224; alpha: 0.99; mom: 0.9; eps: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.226944</td>\n",
       "      <td>2.586566</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.156225</td>\n",
       "      <td>2.149000</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.037098</td>\n",
       "      <td>2.045377</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.009180</td>\n",
       "      <td>2.027908</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.941586</td>\n",
       "      <td>1.877533</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.900887</td>\n",
       "      <td>1.764275</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.812596</td>\n",
       "      <td>1.616052</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.743058</td>\n",
       "      <td>1.499892</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.678959</td>\n",
       "      <td>1.384408</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.606439</td>\n",
       "      <td>1.340591</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.540951</td>\n",
       "      <td>1.255266</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.484519</td>\n",
       "      <td>1.164877</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.456904</td>\n",
       "      <td>1.159018</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.380250</td>\n",
       "      <td>1.088668</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.346210</td>\n",
       "      <td>1.107605</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.307615</td>\n",
       "      <td>1.048542</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.283824</td>\n",
       "      <td>1.042298</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.259815</td>\n",
       "      <td>1.005783</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.241756</td>\n",
       "      <td>0.975511</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.233748</td>\n",
       "      <td>0.993996</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run train.py --woof 1 --size 224 --bs 64 --mixup 0.2  --epoch 20  --lr 1e-2 --arch 'efficientnetB0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01; eff_lr: 0.01; size: 224; alpha: 0.99; mom: 0.9; eps: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.196527</td>\n",
       "      <td>2.428595</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.120789</td>\n",
       "      <td>2.145420</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.047656</td>\n",
       "      <td>2.112224</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>0.718000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.952305</td>\n",
       "      <td>1.972460</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.886277</td>\n",
       "      <td>1.881067</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.821948</td>\n",
       "      <td>1.842069</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.773128</td>\n",
       "      <td>1.953378</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.752273</td>\n",
       "      <td>1.750144</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.687394</td>\n",
       "      <td>1.563101</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.669255</td>\n",
       "      <td>1.573424</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.623035</td>\n",
       "      <td>1.403590</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.585595</td>\n",
       "      <td>1.508838</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.575721</td>\n",
       "      <td>1.328166</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.538499</td>\n",
       "      <td>1.295319</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.536962</td>\n",
       "      <td>1.277336</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.512405</td>\n",
       "      <td>1.320533</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.467631</td>\n",
       "      <td>1.198175</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.462672</td>\n",
       "      <td>1.168166</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.435175</td>\n",
       "      <td>1.198544</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.424037</td>\n",
       "      <td>1.127245</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.387455</td>\n",
       "      <td>1.125938</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.384754</td>\n",
       "      <td>1.174954</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.348491</td>\n",
       "      <td>1.079806</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.342831</td>\n",
       "      <td>1.065017</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.328934</td>\n",
       "      <td>1.054545</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.310963</td>\n",
       "      <td>0.981269</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.310713</td>\n",
       "      <td>1.032858</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.294810</td>\n",
       "      <td>0.967957</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.274998</td>\n",
       "      <td>1.013974</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.260245</td>\n",
       "      <td>0.989311</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.261953</td>\n",
       "      <td>0.953065</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.235245</td>\n",
       "      <td>0.949320</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.229853</td>\n",
       "      <td>0.921928</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.224297</td>\n",
       "      <td>0.939443</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.197560</td>\n",
       "      <td>0.902498</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.199521</td>\n",
       "      <td>0.996083</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.192930</td>\n",
       "      <td>0.919361</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.197829</td>\n",
       "      <td>0.953324</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.168066</td>\n",
       "      <td>0.878837</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.177698</td>\n",
       "      <td>0.932283</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.155826</td>\n",
       "      <td>0.913037</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.133710</td>\n",
       "      <td>0.930069</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.150671</td>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.130400</td>\n",
       "      <td>0.926150</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.120251</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.128292</td>\n",
       "      <td>0.870053</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.115555</td>\n",
       "      <td>0.916024</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.088893</td>\n",
       "      <td>0.930648</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.095444</td>\n",
       "      <td>0.889533</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.095958</td>\n",
       "      <td>0.869151</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.075310</td>\n",
       "      <td>0.942793</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.052430</td>\n",
       "      <td>0.882835</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.051533</td>\n",
       "      <td>0.894602</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.043331</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.029190</td>\n",
       "      <td>0.820553</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.031071</td>\n",
       "      <td>0.865938</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.014067</td>\n",
       "      <td>0.840899</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.013559</td>\n",
       "      <td>0.805909</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.011406</td>\n",
       "      <td>0.861946</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.988326</td>\n",
       "      <td>0.866677</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.970462</td>\n",
       "      <td>0.869487</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.976943</td>\n",
       "      <td>0.832300</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.969428</td>\n",
       "      <td>0.839597</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.966687</td>\n",
       "      <td>0.806766</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.959394</td>\n",
       "      <td>0.822719</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.955072</td>\n",
       "      <td>0.839754</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.939954</td>\n",
       "      <td>0.839872</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.792929</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.943652</td>\n",
       "      <td>0.804847</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.935619</td>\n",
       "      <td>0.852385</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.912522</td>\n",
       "      <td>0.913241</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.919235</td>\n",
       "      <td>0.853240</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.921601</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.917490</td>\n",
       "      <td>0.810594</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.911087</td>\n",
       "      <td>0.804554</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.925108</td>\n",
       "      <td>0.819818</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.914105</td>\n",
       "      <td>0.806176</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.912525</td>\n",
       "      <td>0.826875</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.917259</td>\n",
       "      <td>0.800112</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.847866</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run train.py --woof 1 --size 224 --bs 64 --mixup 0.2  --epoch 80  --lr 1e-2 --arch 'efficientnetB0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01; eff_lr: 0.01; size: 224; alpha: 0.99; mom: 0.9; eps: 1e-06\n",
      "EfficientNet(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (1): MBConv(\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "      (1): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "      (1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "      (1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(40, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "      (1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(40, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "      (1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "      (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "      (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (9): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "      (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "      (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "      (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (12): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "      (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (13): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (15): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): MBConv(\n",
      "    (conv_exp): Sequential(\n",
      "      (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (dw_conv): Sequential(\n",
      "      (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "      (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "    (conv_out): Sequential(\n",
      "      (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(320, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (17): Sequential(\n",
      "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (18): AdaptiveAvgPool2d(output_size=1)\n",
      "  (19): Flatten()\n",
      "  (20): Dropout(p=0.2)\n",
      "  (21): Linear(in_features=1280, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%run train.py --woof 1 --size 224 --bs 64 --mixup 0  --epoch 5  --lr 1e-2 --arch 'efficientnetB0' --dump 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.003; eff_lr: 0.003; size: 224; alpha: 0.99; mom: 0.9; eps: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run train.py --woof 1 --size 224 --bs 64 --mixup 0  --epoch 5  --lr 3e-3 --arch 'efficientnetB0' --lrfinder 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
